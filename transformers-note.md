# Transformers ã®ãƒ¡ãƒ¢

Hugging Face ğŸ¤— ã®ã€‚
LLM ã®ãƒãƒ¼ãƒˆã«æ›¸ã„ã¦ãŸã®ãŒã ã‚“ã ã‚“å¤§ãããªã‚Šã™ããŸã®ã§åˆ†ã‘ã‚‹ã€‚

- [Hugging Face ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆã™æ–¹æ³• (ã¨ãƒªã‚¹ãƒˆã™ã‚‹æ–¹æ³•)](#hugging-face-ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆã™æ–¹æ³•-ã¨ãƒªã‚¹ãƒˆã™ã‚‹æ–¹æ³•)
  - [ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«é–¢ã™ã‚‹å¤ã„æƒ…å ±](#ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«é–¢ã™ã‚‹å¤ã„æƒ…å ±)
- [accelerate](#accelerate)
- [ãƒ¢ãƒ‡ãƒ«ã€ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ](#ãƒ¢ãƒ‡ãƒ«-ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ)
- [pipeline() ã® task ã«ã‹ã‘ã‚‹ã‚‚ã®](#pipeline-ã®-task-ã«ã‹ã‘ã‚‹ã‚‚ã®)
- [PEFT](#peft)
- [Trainer ã® compute_metrics](#trainer-ã®-compute_metrics)
- [accuracy](#accuracy)
- [F1 ã‚¹ã‚³ã‚¢ (F å€¤, F-measure)](#f1-ã‚¹ã‚³ã‚¢-f-å€¤-f-measure)
- [Trainer ã® æå¤±é–¢æ•°(loss function)](#trainer-ã®-æå¤±é–¢æ•°loss-function)
- [fine-tuning ãŒã†ã¾ãã„ã‹ãªã„ã¨ããƒ¡ãƒ¢](#fine-tuning-ãŒã†ã¾ãã„ã‹ãªã„ã¨ããƒ¡ãƒ¢)
- [TensorBoard ã®è–„ã„ã‚°ãƒ©ãƒ•](#tensorboard-ã®è–„ã„ã‚°ãƒ©ãƒ•)
- [Terraformres ã§ä½¿ã† TensorBoard ãƒ¡ãƒ¢](#terraformres-ã§ä½¿ã†-tensorboard-ãƒ¡ãƒ¢)
- [ã‚¿ã‚¹ã‚¯](#ã‚¿ã‚¹ã‚¯)
- [èªè¨¼ãŒå¿…è¦ãªãƒ¢ãƒ‡ãƒ«](#èªè¨¼ãŒå¿…è¦ãªãƒ¢ãƒ‡ãƒ«)
- [chat template](#chat-template)
  - [ãƒ¢ãƒ‡ãƒ«ã® Hugging Face ãƒšãƒ¼ã‚¸ã‚’ç¢ºèªã™ã‚‹](#ãƒ¢ãƒ‡ãƒ«ã®-hugging-face-ãƒšãƒ¼ã‚¸ã‚’ç¢ºèªã™ã‚‹)
  - [ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèª](#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèª)
  - [ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèª](#ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèª)
  - [ãƒ¢ãƒ‡ãƒ«é–‹ç™ºè€…ã® GitHub ãƒªãƒã‚¸ãƒˆãƒªã‚’ç¢ºèª](#ãƒ¢ãƒ‡ãƒ«é–‹ç™ºè€…ã®-github-ãƒªãƒã‚¸ãƒˆãƒªã‚’ç¢ºèª)
  - [ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºè€…ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å•ã„åˆã‚ã›ã‚‹](#ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºè€…ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å•ã„åˆã‚ã›ã‚‹)
- [chat template ã«ã‚ˆã£ã¦ chat ã® input ã¨ã—ã¦ç”Ÿæˆã•ã‚Œã‚‹ token ã®ã‚¤ãƒ¡ãƒ¼ã‚¸](#chat-template-ã«ã‚ˆã£ã¦-chat-ã®-input-ã¨ã—ã¦ç”Ÿæˆã•ã‚Œã‚‹-token-ã®ã‚¤ãƒ¡ãƒ¼ã‚¸)
- [chat template ã®ä¾‹](#chat-template-ã®ä¾‹)
- [vLLM OpenAI Compatible Server ã® chat template](#vllm-openai-compatible-server-ã®-chat-template)

## Hugging Face ã®ãƒ¢ãƒ‡ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ¶ˆã™æ–¹æ³• (ã¨ãƒªã‚¹ãƒˆã™ã‚‹æ–¹æ³•)

```bash
pip install huggingface_hub[cli]
huggingface-cli scan-cache  # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆ—æŒ™ã™ã‚‹
```

ã®ã‚ˆã†ã«ãƒãƒãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã™ã‚‹ã®ãŒæ­£ã—ã„ã£ã½ã„ã€‚

ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®å‰Šé™¤ã¯ `huggingface-cli delete-cache` ã§ TUI ã§å‡ºæ¥ã‚‹ã€‚( `--disable-tui` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚ã‚Š)

ä¾‹:

```console
$ huggingface-cli delete-cache

? Select revisions to delete: 0 revisions selected counting for 0.0.
  â—‹ None of the following (if selected, nothing will be deleted).

Model microsoft/Phi-3-mini-4k-instruct (15.3G, used 2 days ago)
â¯ â—‹ 5fa34190: (detached) # modified 7 months ago
  â—‹ d269012b: (detached) # modified 7 months ago
  â—‹ ff07dc01: (detached) # modified 6 months ago
  â—‹ 0a67737c: main # modified 2 days ago
```

ã“ã‚“ãªæ„Ÿã˜ã«ãªã‚‹ã®ã§ã€ä¸Šä¸‹ã‚­ãƒ¼ã¨ã€ã‚¹ãƒšãƒ¼ã‚¹ã§é¸ã‚“ã§ã€ãƒªã‚¿ãƒ¼ãƒ³ã‚­ãƒ¼ã§æ±ºå®šã€‚
`(detached)` ã®ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ˜ç¤ºçš„ã«ä½¿ã£ã¦ãªã‘ã‚Œã°æ¶ˆã—ã¦ã‚‚ã„ã„ã€‚

å‚è€ƒãƒªãƒ³ã‚¯:

- [Clean your cache](https://huggingface.co/docs/huggingface_hub/guides/manage-cache#clean-your-cache)
- [Using TUI - Manage \`huggingface_hub\` cache-system](https://huggingface.co/docs/huggingface_hub/guides/manage-cache#using-the-tui)
- [huggingface-hub Â· PyPI](https://pypi.org/project/huggingface-hub/)

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«é–¢ã™ã‚‹å¤ã„æƒ…å ±

æ¤œç´¢ã™ã‚‹ã¨
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯

- macOS ã¾ãŸã¯ Linux ã®å ´åˆ: ~/.cache/huggingface
- Windows ã®å ´åˆ: %APPDATA%/huggingface

ã§ã€å¤‰æ›´ã¯ TRANSFORMERS_CACHE ç’°å¢ƒå¤‰æ•°ã§ã€

ãã‚‰ã„ã®ã“ã¨ã¯ã™ãå‡ºã¦ãã‚‹ã®ã§ã™ãŒã€æ­£å¼ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€‚

- [Manage \`huggingface_hub\` cache-system](https://huggingface.co/docs/huggingface_hub/main/guides/manage-cache)
- [Cache management](https://huggingface.co/docs/datasets/cache) - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ(datasets)ã®æ–¹

## accelerate

ä¾¿åˆ©ã€‚PyTorch å°‚ç”¨?

- [accelerate Â· PyPI](https://pypi.org/project/accelerate/) - ã“ã®ã‚µãƒ³ãƒ—ãƒ«ãŒ
- [Using pipeline on large models with ğŸ¤— accelerate:](https://huggingface.co/docs/transformers/pipeline_tutorial#using-pipeline-on-large-models-with-accelerate) - ã“ã£ã¡ã®ã‚µãƒ³ãƒ—ãƒ«ã‚‚
- [huggingface ã® accelerate ã‚’ä½¿ã£ã¦è¨“ç·´æ™‚ã® CUDA out of memory ã‚’å›é¿ã™ã‚‹ #è‡ªç„¶è¨€èªå‡¦ç† - Qiita](https://qiita.com/m__k/items/518ac10399c6c8753763)

## ãƒ¢ãƒ‡ãƒ«ã€ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ

[Load pretrained instances with an AutoClass](https://huggingface.co/docs/transformers/autoclass_tutorial)

ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨ã¯ãƒ¢ãƒ‡ãƒ«ã®éª¨æ ¼ã®ã“ã¨ã§ã‚ã‚Šã€
ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¨ã¯ä¸ãˆã‚‰ã‚ŒãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«å¯¾ã™ã‚‹é‡ã¿ã®ã“ã¨ã§ã‚ã‚‹ã€‚

ä¾‹ãˆã°ã€BERT ã¯ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚Šã€
bert-base-uncased ã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§ã‚ã‚‹ã€‚

ãƒ¢ãƒ‡ãƒ«ã¯ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¾ãŸã¯ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ã©ã¡ã‚‰ã‹ã‚’æ„å‘³ã™ã‚‹ä¸€èˆ¬çš„ãªç”¨èªã§ã‚ã‚‹ã€‚

## pipeline() ã® task ã«ã‹ã‘ã‚‹ã‚‚ã®

```python
['audio-classification', 'automatic-speech-recognition', 'conversational', 'depth-estimation', 'document-question-answering', 'feature-extraction', 'fill-mask', 'image-classification', 'image-segmentation', 'image-to-image', 'image-to-text', 'mask-generation', 'ner', 'object-detection', 'question-answering', 'sentiment-analysis', 'summarization', 'table-question-answering', 'text-classification', 'text-generation', 'text-to-audio', 'text-to-speech', 'text2text-generation', 'token-classification', 'translation', 'video-classification', 'visual-question-answering', 'vqa', 'zero-shot-audio-classification', 'zero-shot-classification', 'zero-shot-image-classification', 'zero-shot-object-detection', 'translation_XX_to_YY']"
```

## PEFT

[PEFT](https://huggingface.co/docs/peft/index)

> PEFT(Parameter-Efficient Fine-Tuning)ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¾®èª¿æ•´ã™ã‚‹ã“ã¨ãªãã€è¨“ç·´æ¸ˆã¿ã®è¨€èªãƒ¢ãƒ‡ãƒ«(PLM)ã‚’æ§˜ã€…ãªä¸‹æµã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«åŠ¹ç‡çš„ã«é©å¿œã•ã›ã‚‹ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚å¤§è¦æ¨¡ãª PLM ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã¯æ³•å¤–ãªã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ãŸã‚ã€PEFT ãƒ¡ã‚½ãƒƒãƒ‰ã¯å°‘æ•°ã®(ä½™åˆ†ãª)ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€è¨ˆç®—ã‚³ã‚¹ãƒˆã¨ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚³ã‚¹ãƒˆã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¾ã™ã€‚æœ€è¿‘ã®æœ€æ–°ã® PEFT æ‰‹æ³•ã¯ã€å®Œå…¨ãªãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã«åŒ¹æ•µã™ã‚‹æ€§èƒ½ã‚’é”æˆã—ã¦ã„ã¾ã™ã€‚
>
> PEFT ã¯ã€DeepSpeed ã¨ãƒ“ãƒƒã‚°ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’æ´»ç”¨ã—ãŸå¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ç”¨ã® Transformers Accelerate ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚

[Load adapters with ğŸ¤— PEFT](https://huggingface.co/docs/transformers/peft)

> PEFT(Parameter-Efficient Fine Tuning)æ³•ã¯ã€fine-tuning ã®éš›ã«äº‹å‰ã«å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‡çµã—ã€ãã®ä¸Šã«å°‘æ•°ã®å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼)ã‚’è¿½åŠ ã™ã‚‹ã€‚ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã¯ã‚¿ã‚¹ã‚¯å›ºæœ‰ã®æƒ…å ±ã‚’å­¦ç¿’ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚Œã‚‹ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€å®Œå…¨ã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã«åŒ¹æ•µã™ã‚‹çµæœã‚’å‡ºã—ãªãŒã‚‰ã€ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãŒéå¸¸ã«é«˜ãã€è¨ˆç®—é‡ãŒå°‘ãªã„ã“ã¨ãŒç¤ºã•ã‚Œã¦ã„ã‚‹ã€‚

Transformers ã® PEFT ãŒã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€æ¨™æº–ã§ã¯

- [Low Rank Adapters (LoRA)](https://huggingface.co/docs/peft/conceptual_guides/lora)
- [IA3](https://huggingface.co/docs/peft/conceptual_guides/ia3)
- [AdaLoRA](https://arxiv.org/abs/2303.10512)

ãªã©ã€‚ãƒªã‚¹ãƒˆã¯ [PEFT - Supported methods](https://huggingface.co/docs/peft/index#supported-methods)

ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚è¿½åŠ å¯èƒ½(ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‚ç…§)

ã‚µãƒãƒ¼ãƒˆã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯
[PEFT - Supported models](https://huggingface.co/docs/peft/index#supported-models)

å‚è€ƒè¨˜äº‹:

- [Load adapters with ğŸ¤— PEFT](https://huggingface.co/docs/transformers/peft)
- [Quicktour](https://huggingface.co/docs/peft/quicktour)
- [[ç¿»è¨³] Hugging face ã® PEFT ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ã‚¢ãƒ¼ #huggingface - Qiita](https://qiita.com/taka_yayoi/items/9196444274d6a63cda76)

ãŸã¨ãˆã°ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
[Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training)ã®
Bert ã§åˆ†é¡ã®å ´åˆã¯
[ã“ã‚Œ](https://huggingface.co/docs/peft/index#sequence-classification)
ã‚’è¦‹ã¦ã€

task_type:

- "SEQ_CLS" - ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®ã‚¯ãƒ©ã‚¹åˆ†é¡(Sequence Classification)ã‚¿ã‚¹ã‚¯
- "SEQ_2_SEQ_LM" - ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é–“ã®å¤‰æ›(Sequence-to-Sequence Language Modeling)ã‚¿ã‚¹ã‚¯ã€‚ä¾‹ãˆã°æ–‡ç« ã®ç¿»è¨³ã€‚
- "CAUSAL_LM" - æœé–¢ä¿‚ã‚’è€ƒæ…®ã—ãŸè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°(Causal Language Modeling)ã‚¿ã‚¹ã‚¯
- "TOKEN_CLS" - ãƒˆãƒ¼ã‚¯ãƒ³ã”ã¨ã®ã‚¯ãƒ©ã‚¹åˆ†é¡(Token Classification)ã‚¿ã‚¹ã‚¯ã€‚ä¾‹ãˆã°ã€å›ºæœ‰è¡¨ç¾æŠ½å‡º(NER)
- "QUESTION_ANS" - è³ªå•å¿œç­”(Question Answering)ã‚¿ã‚¹ã‚¯
- "FEATURE_EXTRACTION" - ãƒ•ã‚£ãƒ¼ãƒãƒ£ãƒ¼ã®æŠ½å‡º(Feature Extraction)ã‚¿ã‚¹ã‚¯

## Trainer ã® compute_metrics

[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)

compute_metrics()é–¢æ•°ã¯ã€Trainer ã® 1 ã‚¨ãƒãƒƒã‚¯çµ‚äº†å¾Œã«å‘¼ã³å‡ºã•ã‚Œã¾ã™
(ã‚¹ãƒˆãƒ©ãƒ†ã‚¸ã«ã‚ˆã£ã¦å¤‰ã‚ã‚‹ã€‚å¾Œè¿°)ã€‚

å…·ä½“çš„ã«ã¯ä»¥ä¸‹ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§å‘¼ã°ã‚Œã¾ã™:

- è¨“ç·´æ™‚ã®å„ã‚¨ãƒãƒƒã‚¯çµ‚äº†å¾Œã«ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ evaluate()ãŒå‘¼ã°ã‚Œã€ãã“ã§ compute_metrics()ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹
- è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã§ evaluate()ãŒå‘¼ã°ã‚ŒãŸã¨ãã«ã€compute_metrics()ãŒå‘¼ã³å‡ºã•ã‚Œã‚‹

è¨“ç·´é€”ä¸­ã§è©•ä¾¡ã—ãŸã„å ´åˆã¯ã€Trainer ã® args ã« evaluation_strategy='steps'ãªã©ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€
æ‰€å®šã®ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã« evaluate()ã—ã€compute_metrics()ã‚’å‘¼ã³å‡ºã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

**compute_metrics()ã®æˆ»ã‚Šå€¤ã¯ã‚ãã¾ã§ä¸­é–“è©•ä¾¡ã®ãŸã‚ã§ã€fine-tuning è‡ªä½“ã«ã¯å½±éŸ¿ã—ãªã„ã€‚**

- [compute_metrics](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.compute_metrics)
- [huggingface/transformers ã® Trainer ã®ä½¿ã„æ–¹ã¨æŒ™å‹• #bert - Qiita](https://qiita.com/nipo/items/44ce3aaf6acd4e2649d1#compute_metrics)

## accuracy

`accuracy = (äºˆæ¸¬ãŒæ­£è§£ã ã£ãŸã‚µãƒ³ãƒ—ãƒ«æ•°) / (å…¨ã‚µãƒ³ãƒ—ãƒ«æ•°)`

ä¾‹ãˆã°ã€100 å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã«å¯¾ã—ã¦ãƒ¢ãƒ‡ãƒ«ãŒ 80 å€‹æ­£è§£ã§ 20 å€‹ä¸æ­£è§£ã ã£ãŸå ´åˆã€accuracy ã¯ 80/100=0.8=80%ã¨ãªã‚Šã¾ã™ã€‚

accuracy ã¯ 0 ã‹ã‚‰ 1 ã®é–“ã®å€¤ã‚’ã¨ã‚Šã€1 ã«è¿‘ã„ã»ã©ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãŒé«˜ã„ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚

åˆ†é¡ã‚¿ã‚¹ã‚¯ã§ã¯ã€accuracy ãŒã‚‚ã£ã¨ã‚‚åŸºæœ¬çš„ã§é‡è¦ãªè©•ä¾¡æŒ‡æ¨™ã® 1 ã¤ã¨ã—ã¦ã€åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚

[Accuracy - a Hugging Face Space by evaluate-metric](https://huggingface.co/spaces/evaluate-metric/accuracy)

## F1 ã‚¹ã‚³ã‚¢ (F å€¤, F-measure)

accuracy ã¯ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦è„†å¼±ãªãŸã‚ã€F1 ã‚¹ã‚³ã‚¢ç­‰ã®æŒ‡æ¨™ã¨åˆã‚ã›ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚

ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã¨ã¯:
ã‚ã‚‹ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ•°ãŒä»–ã®ã‚¯ãƒ©ã‚¹ã«æ¯”ã¹ã¦æ¥µç«¯ã«å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã“ã¨ã§ã™ã€‚
ä¾‹ãˆã°ã€100 å€‹ã®ãƒ‡ãƒ¼ã‚¿ã®å†…ã€90 å€‹ãŒã€Œã‚¯ãƒ©ã‚¹ Aã€ã€10 å€‹ãŒã€Œã‚¯ãƒ©ã‚¹ Bã€ã§ã‚ã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚

ã“ã®å ´åˆã€å˜ç´”ã« accuracy ã‚’è¨ˆç®—ã™ã‚‹ã¨ã€
å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ã€Œã‚¯ãƒ©ã‚¹ Aã€ã¨äºˆæ¸¬ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã‚‚ 90%ã®é«˜ã„ accuracy ãŒå‡ºã¦ã—ã¾ã„ã¾ã™ã€‚

F1 ã‚¹ã‚³ã‚¢ã¯ã€
é©åˆç‡(Precision, Positive predict value,PPV) ã¨
å†ç¾ç‡(Recall)(=æ„Ÿåº¦(Sensitivity)) ã®
èª¿å’Œå¹³å‡ã§ã™ã€‚

- [F å€¤ (è©•ä¾¡æŒ‡æ¨™) - Wikipedia](<https://ja.wikipedia.org/wiki/F%E5%80%A4_(%E8%A9%95%E4%BE%A1%E6%8C%87%E6%A8%99)>)
- [æ„Ÿåº¦ã¨ã‹ç‰¹ç•°åº¦ã¨ã‹ | Tech Blog | CRESCO Tech Blog](https://www.cresco.co.jp/blog/entry/5987.html)
- [F1 - a Hugging Face Space by evaluate-metric](https://huggingface.co/spaces/evaluate-metric/f1)

## Trainer ã® æå¤±é–¢æ•°(loss function)

compute_loss ã§æŒ‡å®šã™ã‚‹ã‚“ã ã‘ã©ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ None.

None ã ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã«åŸºã¥ã„ã¦è‡ªå‹•çš„ã«è¨­å®šã•ã‚Œã¾ã™ã€‚
åˆ†é¡ã‚¿ã‚¹ã‚¯ã®å ´åˆã€BertForSequenceClassification ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€
ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±(äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼)ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¨­å®šã•ã‚Œã¾ã™ã€‚

[æå¤±é–¢æ•°ã¨ã¯?ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’ç†è«–ã€æ©Ÿæ¢°å­¦ç¿’ã€‘ â€“ æ ªå¼ä¼šç¤¾ãƒ©ã‚¤ãƒˆã‚³ãƒ¼ãƒ‰](https://rightcode.co.jp/blog/information-technology/loss-function-neural-network-learning-theory)

## fine-tuning ãŒã†ã¾ãã„ã‹ãªã„ã¨ããƒ¡ãƒ¢

trainer.train()ã®ãƒ­ã‚°ã§ã€loss ãŒã©ã‚“ã©ã‚“å¢—ãˆã¦ 1 ã‚ˆã‚Šå¤§ãããªã‚‹ç¾è±¡ã€‚
å½“ç„¶ã¾ã¨ã‚‚ãªãƒ¢ãƒ‡ãƒ«ã«ãªã‚‰ãªã„ã€‚

```log
{'loss': 0.7373, 'learning_rate': 0.00010506666666666667, 'epoch': 0.16}
{'loss': 0.7517, 'learning_rate': 0.00015840000000000003, 'epoch': 0.24}
{'loss': 0.8197, 'learning_rate': 0.0001986962962962963, 'epoch': 0.32}
{'loss': 0.8381, 'learning_rate': 0.00019277037037037037, 'epoch': 0.4}
{'loss': 0.8572, 'learning_rate': 0.00018684444444444444, 'epoch': 0.48}
{'loss': 1.1329, 'learning_rate': 0.00018097777777777778, 'epoch': 0.56}
{'loss': 1.1242, 'learning_rate': 0.00017505185185185188, 'epoch': 0.64}
{'loss': 1.1402, 'learning_rate': 0.00016912592592592594, 'epoch': 0.72}
{'loss': 1.1246, 'learning_rate': 0.0001632, 'epoch': 0.8}
```

ChatGTP ã«èã„ãŸã‚‰ã‚ã‚Šã¨è¦ªåˆ‡ãªç­”ãˆãŒæ¥ãŸã®ã§ãƒ¡ãƒ¢ã—ã¦ãŠãã€‚

> Hugging Face ã® trainer.train()ãŒ
> {'loss': 1.1118, 'learning_rate': 5.6533333333333336e-05, 'epoch': 2.24}
> ã®ã‚ˆã†ãªãƒ­ã‚°ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã®æ„å‘³ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚

1. **'loss'**: ã“ã®å€¤ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®æå¤±(loss)ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚æå¤±ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸå‡ºåŠ›ã¨å®Ÿéš›ã®æ­£è§£ã¨ã®å·®ã‚’ç¤ºã™æŒ‡æ¨™ã§ã€æœ€å°åŒ–ã•ã‚Œã‚‹ã¹ãç›®æ¨™ã§ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒé€²ã‚€ã«ã¤ã‚Œã¦ã€ã“ã®æå¤±ãŒæ¸›å°‘ã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚
2. **'learning_rate'**: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®å­¦ç¿’ç‡(learning rate)ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚å­¦ç¿’ç‡ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ›´æ–°ã™ã‚‹éš›ã«ä½¿ç”¨ã•ã‚Œã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã®å¤§ãã•ã‚’åˆ¶å¾¡ã™ã‚‹é‡è¦ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒé€²ã‚€ã«ã¤ã‚Œã¦ã€å­¦ç¿’ç‡ãŒå¤‰åŒ–ã™ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã§ã™ã€‚
3. **'epoch'**: ã“ã‚Œã¯ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯æ•°ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚ã‚¨ãƒãƒƒã‚¯ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’ä¸€åº¦å®Œäº†ã™ã‚‹éç¨‹ã§ã™ã€‚ä¾‹ãˆã°ã€'epoch': 2.24 ã¯ã€2 ã‚¨ãƒãƒƒã‚¯ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒã»ã¼å®Œäº†ã—ã€ç¾åœ¨ã®ã‚¨ãƒãƒƒã‚¯ãŒ 2.24 ã§ã‚ã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚

ã“ã‚Œã‚‰ã®ãƒ­ã‚°ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã®é€²æ—ã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã€ç‰¹ã«ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½å‘ä¸Šã‚„å­¦ç¿’ç‡ã®èª¿æ•´ãªã©ã®éš›ã«å½¹ç«‹ã¡ã¾ã™ã€‚

> Hugging Face ã® trainer.train()ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ä½¿ã†æå¤±é–¢æ•°ã¯?

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ cross entropy loss ã‚’æå¤±é–¢æ•°ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚

> cross entropy loss é–¢æ•°ã®çµæœãŒ 1 ã‚’è¶…ãˆã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã‹?

äº¤å·®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±(cross entropy loss)ã®çµæœãŒ 1 ã‚’è¶…ãˆã‚‹ã“ã¨ã¯åŸç†çš„ã«ã‚ã‚Šã¾ã›ã‚“ã€‚

...ã ã‚ˆã­ãˆã€‚

> train ä¸­ã« loss ãŒã©ã‚“ã©ã‚“å¢—ãˆã¦ 1 ã‚’è¶…ãˆã¦ã—ã¾ã„ã¾ã—ãŸã€‚ã“ã‚Œã¯ä½•ãŒåŸå› ã§ã—ã‚‡ã†?

å­¦ç¿’ä¸­ã«æå¤±é–¢æ•°ã®å€¤ãŒå¢—åŠ ã—ã€1 ã‚’è¶…ãˆã¦ã—ã¾ã†åŸå› ã¨ã—ã¦ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªå¯èƒ½æ€§ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

- ã‚ªãƒ¼ãƒãƒ¼ãƒ•ã‚£ãƒƒãƒ†ã‚£ãƒ³ã‚° : ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«éå‰°ã«ãƒ•ã‚£ãƒƒãƒˆã—å§‹ã‚ã€æ±åŒ–æ€§èƒ½ãŒä½ä¸‹ã—ã¦ã„ã‚‹ã€‚
- ãƒ‡ãƒ¼ã‚¿ã®å•é¡Œ : å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«ãƒã‚¤ã‚ºãŒå¤šã„ã€ã‚¢ãƒ³ãƒãƒ©ãƒ³ã‚¹ãªãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒãªã©ã§ãƒ¢ãƒ‡ãƒ«ãŒã†ã¾ãå­¦ç¿’ã§ãã¦ã„ãªã„ã€‚
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å•é¡Œ : å­¦ç¿’ç‡ãŒå¤§ãã™ãã‚‹ã€ã‚¨ãƒãƒƒã‚¯æ•°ãŒå¤šã™ãã‚‹ãªã©ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã®èª¤ã‚Šã€‚
- ãƒãƒƒãƒã‚µã‚¤ã‚ºã®å•é¡Œ : ãƒãƒƒãƒã‚µã‚¤ã‚ºãŒå°ã•ã™ãã‚‹ã¨æå¤±ã®å¤‰å‹•ãŒå¤§ãããªã‚‹ã€‚
- å‹¾é…çˆ†ç™º : å‹¾é…ãŒç™ºæ•£ã—æ•°å€¤çš„ã«å¤§ããªå€¤ã‚’å–ã£ã¦ã—ã¾ã†å•é¡Œã€‚
- ãƒã‚° : æå¤±è¨ˆç®—ã«ãƒã‚°ãŒã‚ã‚‹å¯èƒ½æ€§ã€‚

å¯¾å‡¦ã¨ã—ã¦ã¯ã€å­¦ç¿’æ›²ç·šã‹ã‚‰åŸå› ã‚’ç‰¹å®šã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€æ­£å‰‡åŒ–ã€ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãªã©ã‚’è©¦ã—ã¦ã¿ã‚‹å¿…è¦ãŒã‚ã‚‹ã§ã—ã‚‡ã†ã€‚1 ã‚’å¤§ããè¶…ãˆã‚‹ã‚ˆã†ã§ã‚ã‚Œã°ãƒã‚°ã®å¯èƒ½æ€§ã‚‚è€ƒãˆã‚‰ã‚Œã¾ã™ã€‚

`learning_rate=2e-5` ã‚’ `2e-4` ã«ã—ã¦ã¿ãŸã€‚

```log
{'loss': 0.8198, 'learning_rate': 1.0613333333333334e-05, 'epoch': 0.16}
{'loss': 0.6289, 'learning_rate': 1.5893333333333333e-05, 'epoch': 0.24}
{'loss': 0.5952, 'learning_rate': 1.9863703703703706e-05, 'epoch': 0.32}
{'loss': 0.5745, 'learning_rate': 1.9277037037037037e-05, 'epoch': 0.4}
{'loss': 0.5417, 'learning_rate': 1.8684444444444446e-05, 'epoch': 0.48}
{'loss': 0.5498, 'learning_rate': 1.8097777777777777e-05, 'epoch': 0.56}
{'loss': 0.5138, 'learning_rate': 1.7505185185185186e-05, 'epoch': 0.64}
{'loss': 0.5461, 'learning_rate': 1.6912592592592594e-05, 'epoch': 0.72}
{'loss': 0.533, 'learning_rate': 1.632e-05, 'epoch': 0.8}
```

é †èª¿ã«å­¦ç¿’ã—ã¯ã˜ã‚ãŸã€‚ã‚ˆã‹ã£ãŸã‚ˆã‹ã£ãŸã€‚

## TensorBoard ã®è–„ã„ã‚°ãƒ©ãƒ•

train ã®ã‚°ãƒ©ãƒ•ãªã©ã§

- è–„ã„ç·š: å®Ÿéš›ã®å€¤
- æ¿ƒã„ç·š: TensorBoard ãŒã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‹ã‘ãŸå€¤

ã ãã†ã§ã™ã€‚

## Terraformres ã§ä½¿ã† TensorBoard ãƒ¡ãƒ¢

- `pip install tensorboard` ã—ã¦ã‚ã‚‹
- ã‹ã¤ TrainingArguments ã§ `logging_dir=` ãŒæŒ‡å®šã•ã‚Œã¦ã‚‹

ã¨ã€`logging_dir=` ã§æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ãƒ­ã‚°ãŒä¿å­˜ã•ã‚Œã‚‹ã€‚

VSCode ã ã¨å­¦ç¿’ä¸­ã«è‡ªå‹•ã§ä¸ŠãŒã‚‹ã€‚
ã¾ãŸã¯ã‚³ãƒãƒ³ãƒ‰ãƒ‘ãƒ¬ãƒƒãƒˆã§ `Launch TensorBorad`

æ‰‹å‹•ã§ã¯

```sh
tensorboard --logdir ./logs
```

ã©ã£ã¡ã‚‚ VSCode ã‹ã‚‰ã ã¨ãƒãƒ¼ãƒˆè»¢é€ã—ã¦ãã‚Œã‚‹ã®ã§ã€ãƒªãƒ¢ãƒ¼ãƒˆãƒ›ã‚¹ãƒˆã§ã‚‚æ‰‹å…ƒã§è¦‹ã‚Œã‚‹ã€‚

è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ãŒåŒæ™‚ã«è¡¨ç¤ºã§ãã‚‹ã®ã ã‘ã‚Œã©ã€
logdir ã§æŒ‡å®šã—ãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä»¥ä¸‹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå˜ä½ã§ã€
ãã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ä¸€ç•ªæ–°ã—ã„ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã‚‹ä»•æ›ã‘ã«ãªã£ã¦ã„ã‚‹
(ã†ã¾ãèª¬æ˜ã§ããªã„)ã€‚

è‡ªå‹•ã§ã¯æ›´æ–°ã•ã‚Œãªã„ã¿ãŸã„ã€‚å³ä¸Šã® reload ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã€‚
30 ç§’ã”ã¨ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã‚‹ã€ã¨ã„ã†è©±ã‚‚ã‚ã‚‹ã‘ã©ã€æ›´æ–°ã•ã‚Œãªã‹ã£ãŸ(ä½•ã‹æ¡ä»¶ãŒã‚ã‚‹?)

## ã‚¿ã‚¹ã‚¯

Huggung Face Hub ã® model ã® Natural Language Processing(NLP) ã®ã‚¿ã‚¹ã‚¯ã‚’ã–ã£ãã‚Šè§£èª¬

- Text Classification: ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚ä¾‹ãˆã°ã€æ„Ÿæƒ…åˆ†æã‚„ã‚¹ãƒ‘ãƒ æ¤œå‡ºãªã©ã€‚
- Token Classification: æ–‡ä¸­ã®ãƒˆãƒ¼ã‚¯ãƒ³(å˜èª)ã«ãƒ©ãƒ™ãƒ«ã‚’ä»˜ã‘ã‚‹ã‚¿ã‚¹ã‚¯ã€‚ä¾‹ãˆã°ã€å›ºæœ‰è¡¨ç¾æŠ½å‡ºã‚„æ§‹æ–‡è§£æãªã©ã€‚
- Table Question Answering: ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è³ªå•ã«ç­”ãˆã‚‹ã‚¿ã‚¹ã‚¯ã€‚
- Question Answering: è‡ªç„¶è¨€èªã®è³ªå•ã«å¯¾ã—ã¦é©åˆ‡ã«å›ç­”ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚
- Zero-Shot Classification: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒãªã„æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã®åˆ†é¡ã€‚è»¢ç§»å­¦ç¿’ãŒç”¨ã„ã‚‰ã‚Œã‚‹ã€‚
- Translation: ä¸€è¨€èªã‹ã‚‰åˆ¥ã®è¨€èªã¸ã®ç¿»è¨³ã‚¿ã‚¹ã‚¯ã€‚
- Summarization: é•·æ–‡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚
- Conversational: ä¼šè©±çš„ãªã‚„ã‚Šå–ã‚ŠãŒã§ãã‚‹å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã€‚
- Text Generation: æ¡ä»¶ã«åŸºã¥ãæ–‡ç« ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚
- Text2Text Generation: ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã‚’ç”Ÿæˆã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚
- Fill-Mask: ãƒã‚¹ã‚¯ã•ã‚ŒãŸå˜èªã‚’äºˆæ¸¬ã—ã¦åŸ‹ã‚ã‚‹ã‚¿ã‚¹ã‚¯ã€‚BERT ã®ãƒ—ãƒªãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã€‚
- Sentence Similarity: 2 ã¤ã®æ–‡ã®æ„å‘³çš„ãªé¡ä¼¼åº¦ã‚’è¨ˆç®—ã™ã‚‹ã‚¿ã‚¹ã‚¯ã€‚

æ„å‘³ãŒã‚ˆãã‚ã‹ã‚‰ã‚“ã‚‚ã®ãŒ...

## èªè¨¼ãŒå¿…è¦ãªãƒ¢ãƒ‡ãƒ«

[stabilityai/japanese-stablelm-2-base-1_6b Â· Hugging Face](https://huggingface.co/stabilityai/japanese-stablelm-2-base-1_6b)
ãŒ

"You need to agree to share your contact information to access this model."
ã¨ã„ã†ã‚„ã¤ã ã£ãŸã®ã§ã€

1. ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹
2. ä¸Šè¨˜ã«å¾“ã£ã¦ã‚³ãƒ³ã‚¿ã‚¯ãƒˆæƒ…å ±å…¥ã‚Œã‚‹
3. [Hugging Face â€“ The AI community building the future.](https://huggingface.co/settings/tokens) ã§ token 1 ã¤ä½œã‚‹ã€‚æ¨©é™ã¯ Read ã§ååˆ†ã€‚
4. ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ã‚³ãƒ¼ãƒ‰ã«æ¸¡ã™ã«ã¯ã„ã‚ã‚“ãªæ–¹æ³•ãŒã‚ã‚‹ã‘ã©ã€JSON ã«æ›¸ãã“ã¨ã«ã—ãŸã€‚

`huggingface_token.json`

```json
{
  "HUGGINGFACE_TOKEN": "your_huggingface_api_token"
}
```

ã§ã€ã“ã‚“ãªæ„Ÿã˜ã«ä½¿ã†ã€‚

```python
import json

import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’èª­ã¿è¾¼ã‚€
with open("huggingface_token.json") as f:
    token_data = json.load(f)

token = token_data["HUGGINGFACE_TOKEN"]

# ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ã£ã¦ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€
model_name = "stabilityai/japanese-stablelm-2-base-1_6b"
tokenizer = AutoTokenizer.from_pretrained(
    model_name, token=token, trust_remote_code=True
)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16,
    low_cpu_mem_usage=True,
    device_map="auto",
    trust_remote_code=True,
    token=token,
)
## ã‚ã¨ã¯ https://huggingface.co/stabilityai/japanese-stablelm-2-base-1_6b ã‚’å‚ç…§
```

`trust_remote_code`ã«ã¤ã„ã¦ã¯ä»¥ä¸‹å‚ç…§

- [AutoTokenizer ã§ chiTra ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’èª­ã¿è¾¼ã‚€ #transformers - Qiita](https://qiita.com/mh-northlander/items/0b543edfec2e341bd4a0)
- [Using a model with custom code](https://huggingface.co/docs/transformers/main/en/custom_models#using-a-model-with-custom-code)

## chat template

ãƒ¢ãƒ‡ãƒ«ã”ã¨ã«é•ã†ã‚“ã ã‘ã©... ã©ã†ã‚„ã£ã¦çŸ¥ã£ãŸã‚‰ã„ã„?

å‚è€ƒ:

- [Chat Templates](https://huggingface.co/docs/transformers/main/en/chat_templating)
- [Chat Templates(æ—¥æœ¬èª)](https://huggingface.co/docs/transformers/ja/chat_templating)
- [HuggingFace Transformers ã® ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ã‚’è©¦ã™ï½œ npaka](https://note.com/npaka/n/nf5d78c00b3df)
- [LLM ã®ãƒãƒ£ãƒƒãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ | LLM Japan](https://www.llmjapan.com/blog/chat_template/)

### ãƒ¢ãƒ‡ãƒ«ã® Hugging Face ãƒšãƒ¼ã‚¸ã‚’ç¢ºèªã™ã‚‹

- ãƒ¢ãƒ‡ãƒ«ã® Hugging Face ãƒšãƒ¼ã‚¸ã§ã€ŒFiles and versionsã€ã‚¿ãƒ–ã‚’ç¢ºèª
- `tokenizer_config.json`ã‚„`config.json`å†…ã«`chat_template`ã®å®šç¾©ãŒã‚ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™
- ã¾ãŸã€ãƒ¢ãƒ‡ãƒ«ã® README ã«ã‚‚è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™

### ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèª

ç›´æ¥ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‹ã‚‰ç¢ºèªã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

```python
from transformers import AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("ãƒ¢ãƒ‡ãƒ«å")
if hasattr(tokenizer, "chat_template"):
    print(tokenizer.chat_template)
```

### ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèª

- Llama ç³»: `<s>[INST] {prompt} [/INST]`
- Mistral ç³»: `<s>[INST] {prompt} [/INST]`
- Falcon ç³»: `User: {prompt}\nAssistant:`

ãªã©ã€ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã”ã¨ã«æ¨™æº–çš„ãªãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã™

### ãƒ¢ãƒ‡ãƒ«é–‹ç™ºè€…ã® GitHub ãƒªãƒã‚¸ãƒˆãƒªã‚’ç¢ºèª

- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚„ä¾‹ç¤ºã‚³ãƒ¼ãƒ‰ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
- issues ã‚„ discussions ã§ã‚‚è­°è«–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚

### ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºè€…ã‚„ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«å•ã„åˆã‚ã›ã‚‹

ä¾‹:
[tokyotech-llm/Swallow-7b-instruct-hf Â· tokenizer.chat_template](https://huggingface.co/tokyotech-llm/Swallow-7b-instruct-hf/discussions/2)

ä¾‹ 2:
[llama2:7b-chat/template](https://ollama.com/library/llama2:7b-chat/blobs/2e0493f67d0c)

Ollama ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ Jinja2 ã§ãªãç‹¬è‡ªå½¢å¼ã€‚
<https://github.com/ollama/ollama/blob/main/docs/modelfile.md#template>

## chat template ã«ã‚ˆã£ã¦ chat ã® input ã¨ã—ã¦ç”Ÿæˆã•ã‚Œã‚‹ token ã®ã‚¤ãƒ¡ãƒ¼ã‚¸

Llama ã®å ´åˆã“ã‚“ãªãƒãƒªã«ãªã‚‹ã‚‰ã—ã„ã€‚

```text
<s>[SYSTEM] You are a helpful assistant who provides clear and concise answers. Be polite and informative. [/SYSTEM]
<s>[INST] What is the capital of France? [/INST] Paris
<s>[INST] Who wrote '1984'? [/INST] George Orwell
```

æ”¹è¡ŒãŒå¿…è¦ã‹ã¯ã‚ˆãã‚ã‹ã‚‰ãªã„ã€‚

[Chat Templates](https://huggingface.co/docs/transformers/main/en/chat_templating)
ã®
`tokenizer.apply_chat_template()`
ã®ã‚³ãƒ¼ãƒ‰å‚ç…§ã€‚

## chat template ã®ä¾‹

[microsoft/Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)

ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ä»¥ä¸‹ã®é€šã‚Š (Jinja2):

```jinja
{% for message in messages %}{% if message['role'] == 'system' %}{{'<|system|>
' + message['content'] + '<|end|>
'}}{% elif message['role'] == 'user' %}{{'<|user|>
' + message['content'] + '<|end|>
'}}{% elif message['role'] == 'assistant' %}{{'<|assistant|>
' + message['content'] + '<|end|>
'}}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|assistant|>
' }}{% else %}{{ eos_token }}{% endif %}
```

ã§ã€ã‚µãƒ³ãƒ—ãƒ«ã¯

```text
<|system|>
You are a helpful assistant who provides clear and concise answers. Be polite and informative.<|end|>
<|user|>
Hello, how are you?<|end|>
<|assistant|>
I'm doing great. How can I help you today?<|end|>
<|user|>
I'd like to show off how chat templating works!<|end|>
<|endoftext|>
```

## vLLM OpenAI Compatible Server ã® chat template

[OpenAI Compatible Server ã® Chat Template ã®ã¨ã“ã‚ â€” vLLM](https://docs.vllm.ai/en/v0.4.1/serving/openai_compatible_server.html#chat-template)

`vllm serve --chat-template` ã‚„
`python -m vllm.entrypoints.openai.api_server --chat-template` ã‚„
`from vllm.entrypoints.openai.api_server import run_server` ã®å¼•æ•° `from vllm.engine.arg_utils import AsyncEngineArgs` ã® `chat_template` ã§åˆ†é¡ã®å ´åˆã¯
Jinja2 å½¢å¼ã§ chat ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä¸ãˆã‚‰ã‚Œã‚‹ã‚ˆã†ã«ãªã£ã¦ã‚‹ã‚‰ã—ã„ã€‚

`--chat-template` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å¯ã€‚`./foo.jinja` ã‚„ `/foo/bar.jinja` ã§ã€‚

æœ‰åãƒ¢ãƒ‡ãƒ«ã® chat ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯ä»¥ä¸‹ã«ã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚‹
<https://github.com/vllm-project/vllm/tree/main/examples/>
ã‚“ã ã‘ã©ã€ãªã‚“ã‹ç•°å¸¸ã«ã‚„ã‚„ã“ã—ããªã„?
